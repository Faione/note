## 功能扩展

- 创建内核页表，使能分页机制，建立内核的虚拟地址空间
- 扩展Trap上下文，在保存与恢复Trap上下文的过程中切换页表（即切换虚拟地址空间）
- 建立用于内核地址空间与应用地址空间相互切换所需的跳板空间
- 扩展任务控制块包括虚拟内存相关信息，并在加载执行创建基于某应用的任务时，建立应用的虚拟地址空间
- 改进Trap处理过程和sys_write等系统调用的实现以支持分离的应用地址空间和内核地址空间

### 建立并开启基于分页模式的虚拟地址空间

当 SBI 实现（本项目中基于 RustSBI）初始化完成后， CPU 将跳转到内核入口点并在 S 特权级上执行，此时还并没有开启分页模式，内核的每次访存是直接的物理内存访问
而在开启分页模式之后，内核代码在访存时只能看到内核地址空间，此时每次访存需要通过 MMU 的地址转换。这两种模式之间的过渡在内核初始化期间完成

内存管理子系统进行初始化
1. 初始化全局动态内存分配器
2. 初始化物理页帧管理器
3. 创建内核地址空间并让CPU开启分页模式

```rust
impl PageTable {
    // 按照satp CSR格式要求，构造一个64位无符号整数，使其分页模式为SV39，并将当前多级页表的根节点的物理页号(PageTable中的root_ppn)填充进去
    // token中包含 (分页模式, ASID, 根页表所在物理页号)
    pub fn token(&self) -> usize {
        8usize << 60 | self.root_ppn.0
    }
}

// os/src/mm/memory_set.rs

impl MemorySet {
    // 将多级页表根节点写入当前CPU的 satp CSR，而在此之后，SV39分页模式就被启用了
    pub fn activate(&self) {
        let satp = self.page_table.token();
        unsafe {
            satp::write(satp);
            // 此处使用 sfence.vma 的目的在于清空快表
            asm!("sfence.vma" :::: "volatile");
        }
    }
}
```

todo: ?sfence.vma 可以使得所有发生在它后面的地址转换都能够看到所有排在它前面的写入操作


#### 平滑过度

> 切换 satp 的指令并不是一条跳转指令, pc只是简单的自增当前指令的字长

平滑过度
- 切换 satp 的指令 及其下一条指令这两条相邻的指令的虚拟地址是相邻的, 而它们所在的物理地址一般情况下也是相邻的，但它们所经过的地址转换流程却不同，这是因为在切换 satp 之后, MMU 所查询的多级页表是的不同的
- 平滑过度要求两个地址空间在切换 satp 的指令 附近 的映射满足某种意义的连续性


### 跳板机制的实现

没有分页机制之前，Trap上下文的切换主要进行用户栈的保存(通过 sscratch 寄存器中保存的内核用户栈地址)，Trap上下文的构造，中断处理，中断处理的返回，用户栈的恢复。而在使能分页机制之后，Trap上下文的保存与恢复的过程中，还同时需要完成地址空间的切换(用户地址空间与内核地址空间之间的切换)

具体来说，
- 当 `__alltraps` 保存 Trap 上下文的时候，必须通过修改 `satp` 从应用地址空间切换到内核地址空间，因为 trap handler 只有在内核地址空间中才能访问
- 同理，在 __restore 恢复 Trap 上下文的时候，也必须从内核地址空间切换回应用地址空间，因为应用的代码和数据只能在它自己的地址空间中才能访问，应用是看不到内核地址空间的

这样就要求地址空间的切换不能影响指令的连续执行，即要求应用和内核地址空间在切换地址空间指令附近是平滑的

#### 隔离内核与应用地址空间的思路

**思路A: 隔离**

对内核建立*唯一*的内核地址空间存放内核的代码、数据，同时对于每个应用维护一个它们自己的用户地址空间，因此在 Trap 的时候就需要进行地址空间切换，而在任务切换的时候无需进行（因为这个过程全程在内核内完成）
- Trap 由于应用程序发起/触发系统调用而产生，由于存在特权级的切换，需要执行内核的代码，因此必然会触发 应用地址空间 -> 内核地址空间 的切换，以对 Trap 进行处理
- 任务切换，以分时多任务为例，时钟的中断触发逻辑与应用程序的执行是 `异步` 的，尽管表面上看，应用程序被中断，并切换到 内核地址空间 进行中断处理，但实际任务切换的过程，完全是由内核进行的，其中不涉及的特权级的切换，所以切换的过程无需进行地址空间的切换(可以认为是切换之前已经进入内核，而在切换之后才从内核切出，所以切换过程无需进行地址转换)


**思路B: 共存**

让每个应用都有一个包含应用和内核的地址空间，并将其中的逻辑段分为内核和用户两部分，分别映射到内核/用户的数据和代码，且分别在 CPU 处于 S/U 特权级时访问。此设计中并不存在一个单独的内核地址空间

**比较**

思路B的优势在于:
- Trap 的时候无需切换地址空间，而在任务切换的时候才需要切换地址空间, 在应用*高频进行系统调用*的时候，采用设计方式B能够避免频繁地址空间切换的开销，这通常源于快表或 cache 的失效问题

思路B的缺陷在于:
- 内核核的逻辑段需要在每个应用的地址空间内都映射一次，这会带来一些无法忽略的*内存占用开销*，并显著限制了嵌入式平台（如我们所采用的 K210 ）的任务并发数
- 同时，无法防御针对处理器电路设计缺陷的侧信道攻击，使得恶意应用能够以某种方式间接"看到"内核地址空间中的数据，使得用户隐私数据有可能被泄露

#### Trap上下文放在应用地址空间的次高位置的原因

保存 Trap 上下文到内核栈中之前, 必须完成两项工作：
1. 必须先切换到内核地址空间，这需要将内核地址空间的 token (包含该应用的物理页号) 写入satp 寄存器中
2. 保存应用的内核栈栈顶的位置，这样才能它为基址保存Trap上下文

这意味着在进行切换之前，需要知道内核的两条信息: 内核地址空间的 token, 内核应用栈栈顶的位置，然而 RISC-V 却只提供一个 `sscratch` 寄存器用来进行周转，因此不得不将 Trap 上下文保存在应用地址空间中的一个虚拟页面中，而不是切换到内核地址空间中去保存

### 扩展Trap上下文

```rust
pub struct TrapContext {
    /// general regs[0..31]
    pub x: [usize; 32],
    /// CSR sstatus      
    pub sstatus: Sstatus,
    /// CSR sepc
    pub sepc: usize,
    /// Addr of Page Table
    pub kernel_satp: usize,
    /// kernel stack
    pub kernel_sp: usize,
    /// Addr of trap_handler function
    pub trap_handler: usize,
}
```

- `kernel_satp` 表示应用内核地址空间的token，即内核页表的起始物理地址
- `kernel_sp` 表示当前应用在内核地址空间中的内核栈栈顶的虚拟地址
- `trap_handler` 表示内核中 trap handler 入口点的虚拟地址

以上三个字段在初始化时由内核进行构建，并在此后不再修改

### 切换地址空间

`__alltraps` 首先依然会保存当前应用的程序栈到 sscratch，同时将当前sp修改为用户空间中的 TrapContext 指针
- 在此之前，会将 sp 指向应用内核栈，在内核栈中分配一个 TrapContext 大小的栈上空间，并将当前上下文保存在 TrapContext中，然而现在在用户空间中已经分配了一个 TrapContext，因此 `__alltraps` 要做的就是切换sp为这个 TrapContext 的指针，并将当前程序的上下文保存至其中

```asm
__alltraps:
    csrrw sp, sscratch, sp
    # now sp->*TrapContext in user space, sscratch->user stack
    # save other general purpose registers
    sd x1, 1*8(sp)
    # skip sp(x2), we will save it later
    sd x3, 3*8(sp)
    ...
    # load kernel_satp into t0
    ld t0, 34*8(sp)
    # load trap_handler into t1
    ld t1, 36*8(sp)
    # move to kernel_sp
    ld sp, 35*8(sp)
    # switch to kernel space
    csrw satp, t0
    sfence.vma
    # jump to trap_handler
    jr t1  
```

应用 Trap 进入内核时，硬件会设置一些 CSR 并在 S 特权级下跳转到 `__allstraps` 来进行上下文的保存。整个上下文的保存均发生在用户空间。

完成上下保存之后，则开始准备切换到内核地址空间并跳转到 trap handler，准备工作如下: 
1. 首先将内核地址空间的 token 载入到 t0 寄存器中
2. 然后将 trap handler 入口点的虚拟地址载入到 t1 寄存器中
3. 最后直接将 sp 修改为应用内核栈的地址
以上这些数据，均在初始化时，由内核进行设置

准备好之后，首先将 satp 修改为内核地址空间的 token 并使用 `sfence.vma` 刷新快表，完成地址空间的切换，最后通过 `jr` 指令跳转到 t1 寄存器所保存的 trap handler 入口


```asm
__restore:
    # a0: *TrapContext in user space(Constant); a1: user space token
    # switch to user space
    csrw satp, a1
    sfence.vma
    csrw sscratch, a0
    mv sp, a0
    # now sp points to TrapContext in user space, start restoring based on it
    # restore sstatus/sepc
    ld t0, 32*8(sp)
    ld t1, 33*8(sp)
    csrw sstatus, t0
    csrw sepc, t1
    # restore general purpose registers except x0/sp/tp
    ld x1, 1*8(sp)
    ld x3, 3*8(sp)
    .set n, 5
    .rept 27
        LOAD_GP %n
        .set n, n+1
    .endr
    # back to user stack
    ld sp, 2*8(sp)
    sret
```

`__restore` 用于在内核处理完毕 Trap 后返回到用户态，其接受两个参数:
- a0: Trap 上下文在应用地址空间中的位置(对所有应用来说相同)
- a1: 即将回到的应用的地址空间的 token

`__restore` 首先切换回应用地址空间，然后将传入的 Trap 上下文位置保存到 `sscratch` 寄存器中，并将当前sp修改为 Trap 上下文的位置，随后进行通用寄存器和CSR的恢复，最后通过 `sret` 指令返回用户态

### 建立跳板页面

之前的 `trap.S` 中的代码放置在内核代码中，并设置 `__allstraps` 作为应用程序 Trap处理的 入口, 在加入地址空间之后，则需要考虑切换地址空间前后指令能否能够连续执行
- `__allstraps` 最后才进行了地址空间的切换，在此之前都处于应用地址空间中
- 如果一开始就切换地址空间，就无法保存应用栈上的数据了

而现在 `trap.S` 放置在 `.text.tramploine` 中，使用恒等映射，同时，在应用程序中，使用同样的虚拟页号映射 tramploine 页面，这使得即便切换了地址空间，虚拟地址依然是连续的


在产生trap前后的一小段时间内会有一个比较 极端 的情况，即刚产生trap时，CPU已经进入了内核态（即Supervisor Mode），但此时执行代码和访问数据还是在应用程序所处的用户态虚拟地址空间中，而不是我们通常理解的内核虚拟地址空间。在这段特殊的时间内，CPU指令为什么能够被连续执行呢？这里需要注意：无论是内核还是应用的地址空间，跳板的虚拟页均位于同样位置，且它们也将会映射到同一个实际存放这段汇编代码的物理页帧。也就是说，在执行 __alltraps 或 __restore 函数进行地址空间切换的时候，应用的用户态虚拟地址空间和操作系统内核的内核态虚拟地址空间对切换地址空间的指令所在页的映射方式均是相同的，这就说明了这段切换地址空间的指令控制流仍是可以连续执行的

```rust
// 在所有地址空间中创建跳板页
// 本质是映射了TRAPOLINE(最高虚拟页) 到 实际的 trap.S 物理地址
fn map_trampoline(&mut self) {
    self.page_table.map(
        VirtAddr::from(TRAMPOLINE).into(),
        PhysAddr::from(strampoline as usize).into(),
        PTEFlags::R | PTEFlags::X,
    );
}
```

使用 `jr` 而非 `call` 的原因
问题的本质可以概括为：跳转指令实际被执行时的虚拟地址和在编译器/汇编器/链接器进行后端代码生成和链接形成最终机器码时设置此指令的地址是不同的

### 加载和执行应用程序

#### 扩展任务控制块

```rust
pub struct TaskControlBlock {
    pub task_cx: TaskContext,
    pub task_status: TaskStatus,
    // 应用地址空间
    pub memory_set: MemorySet,
    // 应用次高页面存放的Trap上下文的物理页号
    pub trap_cx_ppn: PhysPageNum,
    // 应用地址空间中从 0x0 开始到用栈结束所包含的字节数
    pub base_size: usize,
}
```

#### 更新对任务控制块的管理

TaskControlBlock 的创建
1. 从 elf 数据创建用户的地址空间
2. 获取应用 trap context 的物理页号( trap context 的虚拟页号的是固定的次高页面)
3. 在内核地址空间中初始化应用的内核栈
4. 设置应用的控制块，初始化 task context(task context 用以进行 __switch 任务切换)
5. 初始化应用的 trap context

```rust
pub fn new(elf_data: &[u8], app_id: usize) -> Self {
    // 从elf中初始化应用地址空间(创建页表，拷贝数据到物理页)
    let (memory_set, user_sp, entry_point) = MemorySet::from_elf(elf_data);
    // 查询应用页表，获得trap上下文的物理地址
    let trap_cx_ppn = memory_set
        .translate(VirtAddr::from(TRAP_CONTEXT).into())
        .unwrap()
        .ppn();
    let task_status = TaskStatus::Ready;

    // 找到当前应用的内核栈的应该放置的位置，并将其实际插入到内核地址空间中
    // 此处并非指栈顶/底，而是栈相在内核地址空间的位置的高位(顶)，低位(底)
    let (kernel_stack_bottom, kernel_stack_top) = kernel_stack_position(app_id);
    KERNEL_SPACE.exclusive_access().insert_framed_area(
        kernel_stack_bottom.into(),
        kernel_stack_top.into(),
        MapPermission::R | MapPermission::W,
    );

    // 在应用的内核栈顶压入 trap_return 而不是 __restore 是为了能够支持对该应用的启动并顺利切换到用户地址空间执行
    let task_control_block = Self {
        task_status,
        task_cx: TaskContext::goto_trap_return(kernel_stack_top),
        memory_set,
        trap_cx_ppn,
        base_size: user_sp,
    };

    // 在用户空间中准备TrapContext
    // 此处在 get_trap_cx 中将trap context物理地址作为裸指针，解引用为 trap context，并初始化其值
    // 尽管 trap context 在应用的地址空间中，但是内核能够对其数据进行操作
    let trap_cx = task_control_block.get_trap_cx();
    *trap_cx = TrapContext::app_init_context(
        entry_point,
        user_sp,
        KERNEL_SPACE.exclusive_access().token(),
        kernel_stack_top,
        trap_handler as usize,
    );

    task_control_block
}
```


#### 改进 Trap 处理的实现

进入内核进行 Trap handle 时，此时 trap 上下文在用户地址空间中，因此需要通过的地址空间的 `current_trap_cx()` 方法手动获得应用的 trap 上下文

完成 trap_handler 之后需要返回用户程序进行执行，考虑的到此时内核中的 `__restore` 为物理地址，需要转化为虚拟地址，才能让MMU正确执行，因此通过计算物理地址上的相对偏移，加上已知的 `TRAP_CONTEXT` 虚拟地址得到 `__restore` 的虚拟地址，将当前应用的 trap_context 与 satp 作为参数传入，进行恢复用户应用执行的步骤

```rust
// 设置应用程序的 stvec
// 获取 TrapContext的虚拟地址，用户空间的token，并计算 __restore 函数的虚拟地址
// 跳转至 __restore 函数
pub fn trap_return() -> ! {
    set_user_trap_entry();
    let trap_ct_ptr = TRAP_CONTEXT;
    let user_satp = current_user_token();
    extern "C" {
        fn __alltraps();
        fn __restore();
    }
    // __alltraps 地址为虚拟地址 TRAMPOLINE，通过偏移量可以计算 __restore 的虚拟地址
    let restore_va = __restore as usize - __alltraps as usize + TRAMPOLINE;
    unsafe {
        asm!(
            "fence.i",
            "jr {restore_va}",
            restore_va = in(reg) restore_va,
            in("a0") trap_ct_ptr,
            in("a1") user_satp,
            options(noreturn)
        );
    }
}
```

#### 改进的 sys_write 实现



 