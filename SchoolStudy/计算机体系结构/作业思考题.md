# 作业与习题

- [作业与习题](#作业与习题)
  - [指令与流水线冲突](#指令与流水线冲突)
    - [(1)](#1)
      - [answer](#answer)
        - [a)](#a)
        - [b)](#b)
        - [c)](#c)
    - [(2)](#2)
      - [answer](#answer-1)
        - [a)](#a-1)
        - [b)](#b-1)
    - [(3)](#3)
      - [answer](#answer-2)
        - [a)](#a-2)
        - [b)](#b-2)
        - [c）](#c-1)
        - [d）](#d)
  - [动态调度](#动态调度)
    - [(1)](#1-1)
      - [answer](#answer-3)
        - [a)](#a-3)
  - [集中式共享Cache一致性](#集中式共享cache一致性)
    - [(1)](#1-2)
      - [answer](#answer-4)
  - [基于目录Cache一致性](#基于目录cache一致性)
    - [(1)](#1-3)
      - [answer](#answer-5)
        - [a)](#a-4)
        - [b)](#b-3)
    - [(2)](#2-1)
      - [answer](#answer-6)
  - [VLIW超长指令字](#vliw超长指令字)
    - [(1)](#1-4)
      - [answer](#answer-7)
    - [(2)](#2-2)
      - [answer](#answer-8)
        - [展开6次](#展开6次)
        - [展开10次](#展开10次)
  - [GPU体系结构](#gpu体系结构)
    - [(1)](#1-5)
      - [answer](#answer-9)
        - [a)](#a-5)
        - [b)](#b-4)

## 指令与流水线冲突

### (1)

- Use the following code fragment:

```s
Loop: 
  LD R1, 0(R2) ; load R1 from address 0+R2
  DADDI R1, R1, #1 ; R1=R1+1
  SD R1, 0(R2) ; store R1 at address 0+R2
  DADDI R2, R2, #4 ; R2=R2+4
  DSUB R4, R3, R2 ; R4=R3-R2
  BNEZ R4, Loop ; branch to Loop if R4!=0
```
- Assume that the initial value of R3 is R2+396.
  - a) Data hazards are caused by data dependences in the code. Whether a dependency causes a hazard depends on the machine implementation (i.e. number of pipeline stages). List all of the data dependences in the code above. Record the register, source instruction, and destination instruction; for example, there is a data dependency for register R1 from the LD to the DADDI.
  - b) Show the timing of this instruction sequence for the 5-stage RISC pipeline without any forwarding or bypassing hardware but assuming that a register read and a write in the same clock cycle “forwards” through the register file, as shown in Figure C.6. Use a pipeline timing chart like that in Figure C.5. Assume that the branch is handled by flushing the pipeline. If all memory references take 1 cycle, how many cycles does this loop take to execute?
  - c) Show the timing of this instruction sequence for the 5-stage RISC pipeline with full forwarding and bypassing hardware. Use a pipeline timing chart like that shown in Figure C.5. Assume that the branch is handled by flushing the pipeline. If all memory references take 1 cycle, how many cycles does this loop take to execute?

#### answer

##### a)

R1 LD DADDI // 数据相关
R1 DADDI SD // 数据相关
R2 LD DADDI // 名称相关
R2 SD DADDI // 名称相关
R2 DSUB DADDI #R2 DADDI DSUB // 数据依赖
R4 BNEZ DSUB #R4 DSUB BNEZ // 数据依赖

##### b)

> 意味着WB与ID可以进行数据流动
> 没有分支预测的前提下，必须再EX阶段后，才能判断之后的指令能否执行

|                  | 1   | 2   | 3     | 4     | 5   | 6     | 7     | 8   | 9   | 10    | 11    | 12  | 13    | 14    | 15  | 16  | 17  | 18  | 19  | 20  | 21  |     |     |     |     |     |
| ---------------- | --- | --- | ----- | ----- | --- | ----- | ----- | --- | --- | ----- | ----- | --- | ----- | ----- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| LD R1, 0(R2)     | IF  | ID  | EX    | MEM   | WB  |       |       |     |     |       |       |     |       |       |     |     |     |     |     |     |     |     |     |     |     |     |     |
| DADDI R1, R1, #1 |     | IF  | stall | stall | ID  | EX    | MEM   | WB  |     |       |       |     |       |       |     |     |     |     |     |     |     |     |     |     |     |     |     |
| SD R1, 0(R2)     |     |     |       |       | IF  | stall | stall | ID  | EX  | MEM   | WB    |     |       |       |     |     |     |     |     |     |     |     |     |     |     |     |     |
| DADDI R2, R2, #4 |     |     |       |       |     |       |       | IF  | ID  | EX    | MEM   | WB  |       |       |     |     |     |     |     |     |     |     |     |     |     |     |     |
| DSUB R4, R3, R2  |     |     |       |       |     |       |       |     | IF  | stall | stall | ID  | EX    | MEM   | WB  |     |     |     |     |     |     |     |     |     |     |     |     |
| R4 DSUB BNEZ     |     |     |       |       |     |       |       |     |     |       |       | IF  | stall | stall | ID  | EX  | MEM | WB  |     |     |     |     |     |     |     |
| LD R1, 0(R2)     |     |     |       |       |     |       |       |     |     |       |       |     |       |       |     |     | IF  | ID  | EX  | MEM | WB  |     |     |     |     |


- 一共循环 396/4 = 99 次
- 总时钟周期 = 16 * 98 + 18 = 1586 
  - 第一次18c，之后每迭代一次增加16
  - 每次加16，最后一次加18c

##### c)

> 旁路可以将当前部件执行的结果直接输入之部件的输入中
> LD必须等待MEM完成才有结果
> 基于冲刷的分支处理，在ID阶段进行分支的处理

|                  | 1   | 2   | 3   | 4     | 5   | 6   | 7   | 8     | 9   | 10  | 11  | 12  | 13  | 14  |
| ---------------- | --- | --- | --- | ----- | --- | --- | --- | ----- | --- | --- | --- | --- | --- | --- |
| LD R1, 0(R2)     | IF  | ID  | EX  | MEM   | WB  |     |     |       |     |     |     |     |     |     |
| DADDI R1, R1, #1 |     | IF  | ID  | stall | EX  | MEM | WB  |       |     |     |     |     |     |     |
| SD R1, 0(R2)     |     |     | IF  | stall | ID  | EX  | MEM | WB    |     |     |     |     |     |     |
| DADDI R2, R2, #4 |     |     |     |       | IF  | ID  | EX  | MEM   | WB  |     |     |     |     |     |
| DSUB R4, R3, R2  |     |     |     |       |     | IF  | ID  | EX    | MEM | WB  |     |     |     |     |
| R4 DSUB BNEZ     |     |     |     |       |     |     | IF  | stall | ID  | EX  | MEM | WB  |     |     |
| Flush            |     |     |     |       |     |     |     |       | IF  | x   | x   | x   | x   |     |
| LD R1, 0(R2)     |     |     |     |       |     |     |     |       |     | IF  | ID  | EX  | MEM | WB  |

- 总时钟周期 = 9*98 + 12 = 9=894
  - 最后一次为12个周期

### (2)

- Suppose the branch frequencies (as percentages of all instructions) are as follows:
  - Conditional branches: 15%
  - Jumps and calls 1%
  - Taken conditional branches 60% are taken
- a) We are examining a four-deep pipeline where the branch is resolved at the end of the second cycle for unconditional branches and at the end of the third cycle for conditional branches. Assuming that only the first pipe stage can always be done independent of whether the branch goes and ignoring other pipeline stalls, how much faster would the machine be without any branch hazards?
- b) Now assume a high-performance processor in which we have a 15-deep pipeline where the branch is resolved at the end of the fifth cycle for unconditional branches and at the end of the tenth cycle for conditional branches. Assuming that only the first pipe stage can always be done independent of whether the branch goes and ignoring other pipeline stalls, how much faster would the machine be without any branch hazards?

#### answer


- $流水化CPI = 理想CPI + 每条指令的停顿时钟周期 = 1 + 每条指令的停顿时钟周期$
  - 理想化的流水化处理器CPI几乎为1
- $加速比 = \frac{流水深度}{ 1 + 每条指令的停顿周期}$
  - 若所有指令的周期数相同，则$非流水化CPI = 流水深度$

##### a)

> 对于此情况
> jump需要重新IF，相比于没有jump的流水线，平均多一个时钟周期
> condition 需要等待EX执行完成，如果不进行分支，则平均多一个时钟周期，如果进行分支，则重新IF，即平均多两个时钟周期

- 每条指令的平均停顿周期 = 1% * 1 + 15% * 60% * 2 + 15% * 40% *1 = 0.24
- $speedup = \frac{4}{1 + 0.24} = 3.23$

##### b)

> 对于此情况
> 第五个时钟周期能判断是否jump, 如jump，则之后执行的第一条指令前4个时钟周期浪费了，相当于推迟流水线4个时钟，平均多4个时钟
> condition在第10个时钟周期判断，若判断通过，则平均多8个时钟周期(下一条指令执行了9个时钟周期，判断通过，则继续执行，相当于等待了8个时钟周期)，若判断分支，则需要重新IF，即多9个时钟周期

- $每条指令的平均停顿周期 = 1% * 4 + 15% * 60% * 9 + 15% * 40% * 9 = 1.33$
- $speedup = \frac{15}{1 + 1.33} = 6.44$


### (3)

- We begin with a computer implemented in single-cycle implementation. When that stages are split by functionality, the stages do not require exactly the same amount of time. The original machine had a clock cycle time of 7ns. After the stages are split, the measured times were IF, 1ns; ID, 1.5ns; EX, 1ns; MEM, 2ns; and WB, 1.5ns. The pipeline register delay is 0.1ns.
- a) What is the clock cycle time of the 5-stage pipelined machine?
- b) If there is a stall every 4 instructions, what is the CPI of the new machine?
- c) What is the speedup of the pipelined machine over the single-cycle machine?
- d) If the pipelined machine had an infinite number of stages, what would its speedup be over the single-cycle machine

#### answer

- $加速比 = \frac{非流水化指令平均时间}{流水化指令平均时间} = \frac{非流水化CPI \times 非流水化时钟周期}{流水化CPI \times 流水化时钟周期} $

##### a)

> 流水线时钟周期为最长段的时间 + 流水时延

2ns + 0.1ns = 2.1

##### b)

- 每条指令平均停顿 1/4 = 0.25 个时钟周期
- CPI = 1 + 0.25 = 1.25

##### c）

- $speedup = \frac{1 * 7 ns}{1.25 * 2.1ns} = 2.67$

##### d）

> 无限流水级，即CPI无限接近于1，时钟周期无限接近于 0.1 

- $speedup = \frac{1 * 7 ns}{1 * 0.1ns} = 70$

## 动态调度

### (1)

- It is critical that the scoreboard be able to distinguish RAW and WAR hazards, because a WAR hazard requires stalling the instruction doing the writing until the instruction reading an operand initiates execution, but a RAW hazard requires delaying the reading instruction until the writing instruction finishes——just the opposite. For example, consider the sequence:

```s
MUL.D F0, F6, F4
DSUB.D F8, F0, F2
ADD.D F2, F10, F2
```

- The DSUB.D depends on the MUL.D (a RAW hazard), thus the MUL.D must be allowed to complete before the DSUB.D. If the MUL.D were stalled for the DSUB.D due to the inability to distinguish between RAW and WAR hazards, the processor will deadlock. This sequence contains a WAR hazard between the ADD.D and the DSUB.D, and the ADD.D cannot be allowed to complete until the DSUB.D begins execution. The difficulty lies in distinguishing the RAW hazard between MUL.D and DSUB.D, and the WAR hazard between the DSUB.D and ADD.D. To see just why the three-instruction scenario is important, trace the handling of each instruction stage by stage through issue, read operands, execute, and write result. Assume that each scoreboard stage other than execute takes 1 clock cycle. Assume that the MUL.D instruction requires 3 clock cycles to execute and that the DSUB.D and ADD.D instructions each take 1 cycle to execute.Finally, assume that the processor has two multiply function units and two add function units. Present the trace as follows
- a) Make a table with the column headings Instruction, Issue, Read Operands, Execute, Write Result, and Comment. In the first column, list the instructions in program order (be generous with space between instructions; larger table cells will better hold the results of your analysis). Start the table by writing a 1 in the Issue column of the MUL.D instruction row to show that MUL.D completes the issue stage in clock cycle 1. Now fill in the stage columns of the table through the cycle at which the scoreboard first stalls an instruction.
- b) For a stalled instruction write the words “waiting at clock cycle X”, where X is the number of the current clock cycle, in the appropriate table column to show that the scoreboard is resolving an RAW or WAR hazard by stalling that stage. In the Comment column, state what type of hazard and what dependent instruction is causing the wait.
- c) Adding the words “completes with clock cycle Y” to a “waiting” table entry, fill in the rest of the table through the time when all instructions are complete. For an instruction that stalled, add a description in the Comments column telling why the wait ended when it did and how deadlock was avoided. (Hint: Think about how WAW hazards are prevented and what this implies about active instruction sequences.) Note the completion order of the three instruction as compared to their program order


#### answer


##### a)

| Instruction       | Issue | Read Operands                  | Execute | Write Result                   | Comment         |
| ----------------- | ----- | ------------------------------ | ------- | ------------------------------ | --------------- |
| MUL.D F0, F6, F4  | 1     | 2                              | 3       | 6                              | First Issue     |
| DSUB.D F8, F0, F2 | 2     | wait at 3<br>complete at 7<br> | 8       | 9                              | wait for MUL.D  |
| ADD.D F2, F10, F2 | 3     | 4                              | 5       | wait at 6<br>complete at 8<br> | wait for DSUB.D |

## 集中式共享Cache一致性

### (1)

- 假设在一个双CPU多处理器系统中，两个CPU用单总线连接，并且采用监听一致性协议（MSI），cache的初始状态均为无效，然后两个CPU对内存中同一块数据进行如下操作：CPU A读、CPU A写、CPU B写、CPU A读，写出每次访问后两个CPU各自的cache的状态变化

#### answer

|   事件   | A状态 | B状态 |
| :------: | :---: | :---: |
| 初始状态 |   I   |   I   |
| CPU A读  |   S   |   I   |
| CPU A写  |   M   |   I   |
| CPU B写  |   I   |   M   |
| CPU A读  |   S   |   S   |

## 基于目录Cache一致性

### (1)

- 在基于目录的Cache一致性系统中，目录记载了P1处理器已经有数据块A的备份
  - a）在哪些情况下，目录又会收到一个P1对A块访问的请求
  - b）如何正确处理上述情况？

#### answer

##### a)

- P1 已经把A替换出去了，随后P1又希望访问 A，因此向目录发出了A 的 miss 请求
- 如果网络不能保证 P1 发出的替换 A 消息和 miss 访问 A 消息达到目录的顺序，后发出的A 的miss请求越过先发出的 A 的替换请求，先到达目录，就会产生上述现象

##### b)

- 两种可行的处理方式
  - 网络保证点到点消息的顺序性
  - 目录发现不一致时，暂缓miss 请求的处理，等待替换消息到达后，目录状态正确后，再返回miss 请求的响应

### (2)

- A、B、C、D为进程P1，P2，P3的共享变量，且初始值均为0，该程序执行结果为D=2000，在基于目录的Cache一致性系统中，运行结果是D=0，请解释原因

|   P1   |       P2       |       P3       |
| :----: | :------------: | :------------: |
| A=2000 | while(B!=1){;} | while(C!=1){;} |
|  B=1   |      C=1       |      D=A       |

#### answer

- 网络不能帮助P1对于A的修改与对于B修改的顺序，若先修改B=1，则会使得P2退出循环，并使得C=1，从而使得P3退出循环，将D赋值为A的初始值0

## VLIW超长指令字

### (1)

- 超长指令字 （VLIW） 设计人员在寄存器使用的体系结构规则方面需要做出一些基本选择。假设 VLIW 设计了自耗尽的执行流水线：一旦启动了操作，其结果将在以后最多 L 个周期出现在目标寄存器中（其中 L 是操作的延迟）。寄存器是永远不够用的，因此希望从现有寄存器中得到最大使用率。请考虑下图
  - 如果负载具有 1 + 2 个周期的延迟，请展开此循环一次，并显示在 没有任何流水线中断或停顿的情况下，每个周期能够进行两次加载和两次添加的 VLIW 如何使用最小数量的寄存器
  - 在存在自耗尽流水线的时，说明一种可能会破坏流水线并产生错误的结果的情况

![](./img/2022-06-15-13-09-17.png)

#### answer

|     | ALU0           | ALU1           | ID/ST        | ID/ST        | BR          |
| --- | -------------- | -------------- | ------------ | ------------ | ----------- |
| 1   | ADDI R11,R3,#2 |                | LW R4, 0(R0) |              |             |
| 2   | ADDI R2,R2,#8  | ADDI R20,R0,#2 |              | LW R5, 8(R1) |             |
| 3   |                |                |              |              |             |
| 4   | ADDI R10,R4,#1 |                |              |              |             |
| 5   | ADDI R10,R4,#1 |                | SW R7,0(R6)  | SW R9,8(R8)  |             |
| 6   |                | SUB R4,R3,R2   |              |              |             |
| 7   |                | SUB R4,R3,R2   |              |              | BNZ R4,Loop |

- 如果在时钟周期1和4之间进行了中断，那么周期2的LW的结果将以R1结束，而不是周期1的LW
  - bank stalls和ECC stalls也会造成同样的流水线清空，最后一个作者获胜，这是一个典型的RAW，所有其他的“中间”结果都丢失了

### (2)

- 假设一个 VLIW 处理器的指令包含五个操作，如图所示。我们将比较两个循环展开的程度。首先，展开循环 6 次以获取并规划ILP，使其没有任何stall（即完全空的事件周期），折叠循环开销指令。并重复该方法但展开循环10 次。忽略分支延迟间隙。写出两个规划。每个规划的结果向量的每个元素的执行时间是多少？每个规划中使用的操作间隙的百分比是多少？两个规
划之间的代码大小有多大差异？这两个规划的总寄存器需求是多少？

![](./img/2022-06-15-13-10-39.png)

#### answer

##### 展开6次

![](./img/2022-06-16-23-02-09.png)

- 展开6次时，在15个周期内进行了34 次操作，指令发射速率为每周期2.67个操作
- VLIW一共有75个操作槽，所以效率为34/75=45.3%
- 此次代码展开一共需要12个FP寄存器

##### 展开10次

![](./img/2022-06-16-23-03-04.png)

- 展开10次时，在17个周期内进行了54 次操作 ，指令发射速率为每周期3.18个操作
- VLIW一共有85个操作槽，所以效率为54/85=63.5%
- 此次代码展开一共需要20个FP寄存器

## GPU体系结构

### (1)

- 假定有一种包含10个 SIMD 处理器的 GPU 体系结构。每条 SIMD 指令的宽度为32，每个SIMD 处理器包含8个车道（lane）,用于执行单精度运算和载入/存储指令，也就是说，每个非分岔 SIMD 指令每4个时钟周期可以生成32个结果。假定内核的分岔分支将导致平均80%的线程为活动的。假定在所执行的全部 SIMD 指令中，70%为单精度运算、20%为载入/ 存储。由于并不包含所有存储器延迟，所以假定 SIMD 指令平均发射率为0.85。假定 GPU 的时钟速度为1.5 GHZ
- a. 计算这个内核在这个GPU上的吞吐量,单位为GFLOP/S
- b. 假定我们有以下选项
  1. 将单精度车道数增大至16
  2. 将SIMD处理器数增大至15 (假定这一改变不会影响所有其他性能度量,代码会扩展到增加的处理器上)
  3. 添加缓存可以有效地将存储器延迟缩减40%，这样会将指令发射率增加至0.95，对于这些改进中的每一项
  - 吞吐量的加速比为多少

#### answer

##### a)

- 10 * (32/4) * 1.5 * 0.8 * 0.7 * 0.85 =  57.12 GFLOP/s

##### b)

**1.**

- 10 * 16 * 1.5 * 0.8 * 0.7 * 0.85 = 114.24 GFLOP/s
- speedup = 2

**2.**

- 15 * 8 * 1.5 * 0.8 * 0.7 * 0.85 = 85.68 GFLOP/s
- speedup = 1.5

**3.**

- 10 * 8 * 1.5 * 0.8 * 0.7 * 0.95 = 63.84 GFLOP/s
- speedup = 1.1
  




