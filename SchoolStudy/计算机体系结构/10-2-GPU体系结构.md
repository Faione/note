# GPU体系结构

- [GPU体系结构](#gpu体系结构)
  - [一、GPU基本硬件结构](#一gpu基本硬件结构)
  - [二、编程模型](#二编程模型)
    - [(1) 编程模型1: Sequential SISD](#1-编程模型1-sequential-sisd)
    - [(2) 编程模型2: Data Parallel（SIMD）](#2-编程模型2-data-parallelsimd)
    - [(3) 编程模型3: 多线程](#3-编程模型3-多线程)
    - [(4) GPU Kernel执行](#4-gpu-kernel执行)
  - [三、GPU存储结构](#三gpu存储结构)

## 一、GPU基本硬件结构

- CPU+GPU异构体系结构
  - 推动异构计算的发展
  - 针对每个任务选择合适的处理器和存储器
- 通用CPU 适合执行一些串行的线程
  - 串行执行快
  - 带有cache，访问存储器延时低
- GPU适合执行大量并行线程
  - 可扩展的并行执行
  - 高带宽的并行存取

**多核CPU vs 多线程结构**

- 多核处理器结构随着线程数的增加会落入性能低谷
- 当线程数较少时多线程结构（GPU）会落入性能低谷

## 二、编程模型

- 三种编程模式来挖掘程序的并行性:
  1. Sequential (SISD)
  2. Data-Parallel (SIMD)
  3. Multithreaded (MIMD/SPMD)

### (1) 编程模型1: Sequential SISD

- 硬件来做循环展开

### (2) 编程模型2: Data Parallel（SIMD）

- 要求: 各循环之间相互独立的，没有数据依赖
- 思路: 程序员或编译器生成SIMD指令，所有的循环执行相同的指令，处理不同的数据

### (3) 编程模型3: 多线程

- 要求: 各循环之间相互独立的，没有数据依赖
- 思路: 程序员或编译器为每次循环生成一个线程, 每个线程执行同样的指令流，处理不同的数据

**SPMD**

> Single procedure/program, multiple data

- 每个处理单元执行同样的过程，处理不同的数据
  - 这些过程可以在程序中的某个点上同步，例如 barriers
- 多条指令流执行相同的程序
  - 每个程序/过程
    - 操作不同的数据
    - 运行时可以执行不同的控制流路径
- 许多科学计算应用以这种方式编程，运行在MIMD硬件结构上 (multiprocessors)
- 现代通用 GPUs 以这种类似的方式编程，运行在SIMD硬件上

**A GPU is a SIMD（SIMT）Machine**

- GPU不是用SIMD指令编程
  - 使用线程 (SPMD 编程模型)
  - 每个线程执行同样的代码，但操作不同的数据元素
  - 每个线程有自己的上下文(即可以独立地启动/执行等）
- 一组执行相同指令的线程由硬件动态组织成warp
  - 一个warp是由硬件形成的SIMD操作
  - Lockstep模式执行

**Threads and Blocks**

- Thread
  - 一个线程（Thread）对应一个数据元素
- Block
  - 大量的线程组织成很多线程块（Block）
- Grid
  - 许多线程块组成一个网格（Grid）
- GPU 由硬件对线程进行管理
  - Thread Block Scheduler
  - SIMD Thread Scheduler
  - Warp
    - SIMD线程
    - 线程调度的基本单位

### (4) GPU Kernel执行

1. 将输入数据从内存传输到GPU显存
2. 启动kernel
3. 等待kernel完成（如果是同步的）
4. 将结果传输到内存

- 数据传输主导执行时间 
- 具有统一地址空间的集成显卡没有拷贝，但是CPU和GPU会竞争内存

## 三、GPU存储结构

