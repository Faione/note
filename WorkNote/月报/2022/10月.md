---
marp: true
theme: gaia
<!-- $theme: gaia -->

---

# 十月工作汇报

方浩镭

---

- agent优化
- 算力度量对接
- Service Map
- Ray\Openshift接入
- 北京演示环境


---

## agent优化


---

### a) 编译优化

- 增加生产环境编译选项
  - 缩小36%可执行文件大小
- 关闭CGO进行纯静态编译，增加agent的可移植性
  - 可以直接运行在原生apline容器中
- 增加条件编译，以进行一步缩小可执行文件大小

---

### b) 镜像构建优化

- 多阶段镜像构建
  - 在容器进行编译，搭配vendor使用, 减小对编译环境的依赖
- 将监控组件配置与工具打包为单独镜像，与agent解耦
- 优化镜像构建步骤，去除多余的文件读写
  - 减小50%的agent镜像大小

---

### c) 架构优化

- 加入依赖注入模块
  - 简化了 agent 代码结构
  - 方便进行新功能模块的开发与对编译的控制

---

## 算力度量对接


---

### a) perf-exporter


基于较成熟的prometheus生态开发, 核心是对于文件写入的监控，类似 `tail -f`

当 perf stat 产生写入时，exporter会响应并对新写入的数据进行解析，取出关键数据，然后更新或创建相关event指标

---

#### 特点

- 采用pushgateway模式
  - 在 perf 运行之前首先向 pushgateway 注册，然后不断推送数据，并在 perf 运行完成之后进行注销
- 支持自定义的指标，允许将任意的label加入指标之中
  - 可以使用guid对采集对象进行标注
- 提供了一个基础镜像
  - 可以基于此进行算力应用进行构建

---

#### 聚合

在prometheus采集中，加入聚合规则，进行进一步的统计计算，满足算力度量组对于和数据的需求
- 聚合浮点事件总和，总指令事件，以及 95 分位数


---

## Service Map

---

### a) cilium exporter

- 使用gRpc与cilium交互
  - 收集原始 flow 数据，并持续接受 flow 数据推送，及时更新相应指标
- 提供 summary/count 类型指标，监控 tcp/http 数据
  - 用来进行 service map 的构造，以及latency指标的收集

---

#### 接入监控系统

1. 基于 serviceMonitor 来与 集群中的 prometheus operator 作用
2. 提供 k8s service discovery 的方案
3. 支持helm部署，作为 agent 监控组件的一部分

---

### b) 网络分组

- 分组网络的核心在于标签
  - 利用K8s的标签选择器对分组进行选择, 然后再基于CNP来限制这些pod, 使得他们仅能接受来自分组内的流量
  - 基于 L4 ciliumNetWorkPolicy(CNP) 进行 ingree/egress 流量限制
- 允许pod同时存在与多个分组中
- 提供了跨 namespace 的网络分组

---

## Ray\Openshift接入,北京演示环境

---

### a) KubeRay

- 本质是一个通过k8s运行并托管的Ray集群
- 当前在南京测试集群中完成了kubeRay的搭建与测试，同时调研了ClusterMesh方案，计划通过Mesh Cluster的方式来进行Ray的跨地域调度

---

### b) 北京演示环境 

- 协助进行北京演示环境的搭建，完成2台虚拟机，1个虚拟集群，1台树莓派及1台服务器(台式机)上的监控环境部署
- 修复agent中监控配置注入的bug，改进部署流程，使得agent完全支持容器部署方式，同时编写helm chart, 让agent同时支持helm部署的方式

### c) 在南京测试集群中完成最小化Openshift环境的搭建


