# 动态网络路由实验

<p align="right">学号: 2021E8013282148</p>
<p align="right">姓名: 方浩镭</p>

- [动态网络路由实验](#动态网络路由实验)
  - [一、实验内容](#一实验内容)
    - [(1) 实验内容一](#1-实验内容一)
    - [(2) 实验内容二](#2-实验内容二)
  - [二、实验流程](#二实验流程)
    - [(1) mospf功能完善](#1-mospf功能完善)
    - [(2) 实验一](#2-实验一)
    - [(3) 实验二](#3-实验二)
  - [三、思考题](#三思考题)
## 一、实验内容

### (1) 实验内容一

- 基于已有代码框架，实现路由器生成和处理mOSPF Hello/LSU消息的相关操作，构建一致性链路状态数据库

- 运行实验
   - 运行网络拓扑(topo.py)
   - 在各个路由器节点上执行disable_arp.sh, disable_icmp.sh, disable_ip_forward.sh)，禁止协议栈的相应功能
   - 运行./mospfd，使得各个节点生成一致的链路状态数据库

### (2) 实验内容二

- 基于实验一，实现路由器计算路由表项的相关操作
- 运行实验
   - 运行网络拓扑(topo.py)
   - 在各个路由器节点上执行disable_arp.sh, disable_icmp.sh, disable_ip_forward.sh)，禁止协议栈的相应功能
   - 运行./mospfd，使得各个节点生成一致的链路状态数据库
   - 等待一段时间后，每个节点生成完整的路由表项
   - 在节点h1上ping/traceroute节点h2
   - 关掉某节点或链路，等一段时间后，再次用h1去traceroute节点h2
## 二、实验流程

### (1) mospf功能完善

**sending_mospf_hello_thread**

```c++
void *sending_mospf_hello_thread(void *param)
{
	while(1){
        pthread_mutex_lock(&mospf_lock);

		int len = ETHER_HDR_SIZE + IP_BASE_HDR_SIZE + MOSPF_HDR_SIZE + MOSPF_HELLO_SIZE;
		static u8 d_mac[ETH_ALEN] = {0x01,0x00,0x5e,0x00,0x00,0x05};
		char *packet = malloc(len);
		bzero(packet, len);

		// ethernet 头
		struct ether_header* eh = (struct ether_header*)(packet);
		memcpy(eh->ether_dhost, d_mac, ETH_ALEN);
		eh->ether_type = htons(ETH_P_IP);

		iface_info_t *iface_entry = NULL;
		list_for_each_entry(iface_entry, &instance->iface_list, list) {
			memcpy(eh->ether_shost, iface_entry->mac, ETH_ALEN);
            
			// ip头
			struct iphdr* iph = packet_to_ip_hdr(packet);
			ip_init_hdr(iph, iface_entry->ip, MOSPF_ALLSPFRouters, len - ETHER_HDR_SIZE, IPPROTO_MOSPF);
			iph->ttl = 1;

            // mospf头
			struct mospf_hdr* mospf_h = (struct mospf_hdr*)((char*)iph + IP_HDR_SIZE(iph));
			mospf_init_hdr(mospf_h, MOSPF_TYPE_HELLO, MOSPF_HDR_SIZE, instance->router_id, 0);

			// mospf hello 		
			struct mospf_hello* mospf_hl = (struct mospf_hello*)((char*)mospf_h + MOSPF_HDR_SIZE);	
			mospf_init_hello(mospf_hl, iface_entry->mask);
			mospf_h->checksum = mospf_checksum(mospf_h);

			iface_send_packet(iface_entry, packet, len);
		}
		free(packet);

		pthread_mutex_unlock(&mospf_lock);
		sleep(MOSPF_DEFAULT_HELLOINT);
	}
	return NULL;
}
```

**checking_nbr_thread**

```c++
void *checking_nbr_thread(void *param)
{
	while(1){
		sleep(1);		
		int doLsu = 0;
		pthread_mutex_lock(&mospf_lock);

		iface_info_t *iface_entry = NULL;
		list_for_each_entry(iface_entry, &instance->iface_list, list) {
			mospf_nbr_t *nbr_entry = NULL;
			list_for_each_entry(nbr_entry, &(iface_entry->nbr_list),list){
				if (++(nbr_entry->alive) > 3 * MOSPF_DEFAULT_HELLOINT) {
					free(nbr_entry);
					list_delete_entry(&nbr_entry->list);
					iface_entry->num_nbr--;
					sending_mospf_lsu();		
				}
			}
		}

		pthread_mutex_unlock(&mospf_lock);
	}
	return NULL;
}
```

**handle_mospf_hello**

```c++
void handle_mospf_hello(iface_info_t *iface, const char *packet, int len)
{
	struct iphdr *iph = packet_to_ip_hdr(packet);
	struct mospf_hdr *mospf_h = (struct mospf_hdr *)((char*)iph + IP_HDR_SIZE(iph));
	struct mospf_hello *mospf_hl = (struct mospf_hello*)((char*)mospf_h + MOSPF_HDR_SIZE);

    u32 ip = ntohl(iph->saddr);
	u32 id = ntohl(mospf_h->rid);
	u32 mask = ntohl(mospf_hl->mask);
	
	mospf_nbr_t *entry = NULL, *selected = NULL;
	pthread_mutex_lock(&mospf_lock);
	list_for_each_entry(entry, &(iface->nbr_list),list){
		if(entry->nbr_id == id){
			selected = entry;
			selected->alive = 0;
			break;
		}
	}

	if(selected == NULL){
		iface->num_nbr = iface->num_nbr + 1;
		mospf_nbr_t* insert_temp;
		insert_temp = (mospf_nbr_t*)malloc(sizeof(mospf_nbr_t));
		insert_temp->nbr_id = id;
		insert_temp->nbr_ip = ip;
		insert_temp->nbr_mask = mask;
		insert_temp->alive = 0;

		list_add_tail(&(insert_temp->list), &(iface->nbr_list));

		sending_mospf_lsu();		
	}
	free(packet);

	pthread_mutex_unlock(&mospf_lock);
}
```

**sending_mospf_lsu**

```c++
void sending_mospf_lsu(){
	// 计算邻居节点个数
	int nbr_n = 0;

	iface_info_t * iface_entry = NULL;
	list_for_each_entry (iface_entry, &instance->iface_list, list) { 
		if (iface_entry->num_nbr == 0) {
			nbr_n ++;
		} else {
			nbr_n += iface_entry->num_nbr;
		}	
	}

	struct mospf_lsa nbr_array [nbr_n + 1];
	bzero(nbr_array, (nbr_n + 1) * MOSPF_LSA_SIZE);

	int pos = 0;
	iface_entry = NULL;
	list_for_each_entry (iface_entry, &instance->iface_list, list) {
		if (iface_entry->num_nbr == 0) { // 端口没有相邻节点
			nbr_array[pos].mask = htonl(iface_entry->mask);
			nbr_array[pos].network = htonl(iface_entry->ip & iface_entry->mask);
			nbr_array[pos].rid = 0;
			pos++;
		} else {
			mospf_nbr_t * nbr_pos = NULL;
			list_for_each_entry (nbr_pos, &iface_entry->nbr_list, list) {
				nbr_array[pos].mask = htonl(nbr_pos->nbr_mask);
				nbr_array[pos].network = htonl(nbr_pos->nbr_ip & nbr_pos->nbr_mask);
				nbr_array[pos].rid = htonl(nbr_pos->nbr_id);
				pos++;
			}
		}	
	}
	int len = ETHER_HDR_SIZE + IP_BASE_HDR_SIZE + MOSPF_HDR_SIZE + MOSPF_LSU_SIZE + nbr_n * MOSPF_LSA_SIZE;

    // 更新序列号
	instance->sequence_num++; 

    // 发送链路状态信息
	iface_entry = NULL;
	list_for_each_entry (iface_entry, &instance->iface_list, list) { 
		mospf_nbr_t * nbr_pos = NULL;
		list_for_each_entry (nbr_pos, &iface_entry->nbr_list, list) {
			char * packet = malloc(len);
			bzero(packet, len);

			struct ether_header *eh = (struct ether_header *)packet;
			struct iphdr *ip_hdr = packet_to_ip_hdr(packet);
			struct mospf_hdr * mospf_header = (struct mospf_hdr *)((char*)ip_hdr + IP_BASE_HDR_SIZE);
			struct mospf_lsu * lsu = (struct mospf_lsu *)((char*)mospf_header + MOSPF_HDR_SIZE);

			eh->ether_type = htons(ETH_P_IP);
			memcpy(eh->ether_shost, iface_entry->mac, ETH_ALEN);

			ip_init_hdr(ip_hdr, iface_entry->ip, nbr_pos->nbr_ip, len - ETHER_HDR_SIZE, IPPROTO_MOSPF);

			mospf_init_hdr(mospf_header, MOSPF_TYPE_LSU, len - ETHER_HDR_SIZE - IP_BASE_HDR_SIZE, instance->router_id, instance->area_id);

			mospf_init_lsu(lsu, nbr_n);
			memcpy(packet + ETHER_HDR_SIZE + IP_BASE_HDR_SIZE + MOSPF_HDR_SIZE + MOSPF_LSU_SIZE, nbr_array, nbr_n * MOSPF_LSA_SIZE);

			mospf_header->checksum = mospf_checksum(mospf_header);
			ip_send_packet(packet, len);
		}
	}	
}
```

### (2) 实验一

在路由器节点上运行 mospfd-reference 程序, 等待一段时间后, 主机节点 h1 与 h2 能够相互 ping 通

```shell
$h1 traceroute 10.0.6.22
traceroute to 10.0.6.22 (10.0.6.22), 30 hops max, 60 byte packets
 1  10.0.1.1 (10.0.1.1)  0.128 ms  0.080 ms  0.072 ms
 2  10.0.3.3 (10.0.3.3)  0.178 ms  0.224 ms  0.255 ms
 3  10.0.4.4 (10.0.4.4)  0.575 ms  0.574 ms  0.571 ms
 4  10.0.6.22 (10.0.6.22)  0.483 ms  0.475 ms  0.471 ms
```

### (3) 实验二

断开路由之间的连接来改变网络拓扑, 等待一段时间后, 路由能够收敛

```shell
# 断开 r3 r4 的连接
>mininet link r3 r4 down

# 一段时间后
$h1 traceroute 10.0.6.22
traceroute to 10.0.6.22 (10.0.6.22), 30 hops max, 60 byte packets
 1  10.0.1.1 (10.0.1.1)  0.98 ms  0.092 ms  0.043 ms
 2  10.0.2.2 (10.0.2.2)  0.112 ms  0.234 ms  0.156 ms
 3  10.0.4.4 (10.0.4.4)  0.167 ms  0.265 ms  0.245 ms
 4  10.0.6.22 (10.0.6.22)  0.256 ms  0.278 ms  0.231 ms

```

## 三、思考题

1. 在构建一致性链路状态数据库中，为什么邻居发现使用组播(Multicast)机制，链路状态扩散用单播(Unicast)机制？

答: 组播机制能够有效应对单一节点像多个节点发送数据的情况, 邻居发现和链路状态扩散都符合这种情况，但是两者在要扩散的数据上存在差异，邻居发现发送 Hello Message, 发送频率相较于LSU更高, 而其中的数据相对来说更简单, 对数据的准确性要求不高, 因而使用组播机制以减轻网络负载, 而LSU中的, 需要发送的是链路的状态的信息, 其随链路的扩大而复杂，同时链路状态信息对计算正确的路由信息来说至关重要，因而选择单播提供确认机制来增强信息的准确率

2. 该实验的路由收敛时间大约为20-30秒，网络规模增大时收敛时间会进一步增加，如何改进路由算法的可扩展性？

答: 网络规模较大的时候, 可对网络进行进一步的划分, 在较小的网络区域中, 路由的收敛效率能够得到保证, 而在区域之间的数据交换, 通过设置边缘路由来完成, 同时, 这些边缘路由也可以认为一个区域, 其路由信息同样可以进行计算优化  

3. 路由查找的时间尺度为~ns，路由更新的时间尺度为~10s，如何设计路由查找更新数据结构，使得更新对查找的影响尽可能小？

答: 更新与查找操作中涉及到锁的使用, 路由表正在更新时, 不允许进行查找，这使得原本尺度更小的查找操作收到的了更新操作的影响, 因此, 优化数据结构就需要考虑锁的存在，防止将整个数据表视为整体进行加锁操作, 考虑到路由更新往往是局部操作, 因此可以参考内存分页的机制，将路由数据按照某种条件进行分页, 更新时仅仅锁住某一页, 而不会影响对其他页的查找，这样就能够减少对查找操作的影响